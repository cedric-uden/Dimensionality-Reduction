\begin{itemize}
	\item Primarily used for feature extraction \cite{PythonMachineLearningCh5}
	\item Is an eigenvector problem \cite{MultilinearSubspaceLearningCh2}
	\item Will try our best to give a quick overview
	\item Very old and relevant topic
	\item First approaches made in 1901 using simple projections. \cite{pearson1901liii}
	\item Unsupervised method \cite{PythonMachineLearningCh5}
	\item Will take a look at the standard approach and the modern way (svd)
	\item scikit implements this \cite{tipping1999mixtures}
\end{itemize}



% \subsubsection{Intro}
% \clearpage

% \subsubsection{History}
% \clearpage

% \subsubsection{PCA in detail}
% Scikit implementation \cite{Tipping:2006va}
% \ \clearpage
% \ \clearpage
% \ \clearpage
% \ \clearpage

% \subsubsection{Minka's method to guess intrinsic dimensionality}
% \ \clearpage
% \ \clearpage

% \subsubsection{introduction to svd}
% \ \clearpage
% \ \clearpage

% \subsubsection{svd: full method}
% \ \clearpage
% \ \clearpage

% \subsubsection{svd: ARPACK}
% \ \clearpage
% \ \clearpage

% \subsubsection{svd: randomized}
% \ \clearpage
% \ \clearpage

% \paragraph{full \gls{svd}} \label{svd}

% According to \cite{wright2001large}

% $$\bigo{N^3}$$

% \clearpage

% \paragraph{\gls{arpack}}

% According to \cite{wright2001large}

% $$\bigo{N^2}$$

% \clearpage

% \paragraph{randomised}

% According to this \cite{HandsOnMLCh8}

% $$\bigo{d^3}$$


% \clearpage

% \paragraph{Conclusion}
